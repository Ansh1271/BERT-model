{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_BYtGhXnRoKQ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PndPtv1eR9j5",
        "outputId": "b5d41ea6-e4e3-4aed-a77d-120b4edcfe04"
      },
      "outputs": [],
      "source": [
        "# Step 2: Load and prepare the dataset\n",
        "data = pd.read_csv(\"updating_multiclass_dataset.csv\")  # Replace with your actual file path\n",
        "\n",
        "# Display the first few rows to check the data structure\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "# Map sentiments to integers (Adjust these mappings according to your dataset)\n",
        "sentiment_mapping = {'positive': 2, 'negative': 0, 'neutral': 1}\n",
        "data['Label'] = data['Sentiment'].map(sentiment_mapping)\n",
        "\n",
        "# Check for NaN values in the 'Label' column\n",
        "if data['Label'].isnull().any():\n",
        "    print(\"NaN values found in labels. Please check your mapping.\")\n",
        "    print(data[data['Label'].isnull()])  # Print rows with NaN labels\n",
        "else:\n",
        "    print(\"All labels are mapped correctly.\")\n",
        "\n",
        "# Create a Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "6cf1ad2d780744bda925669014d94acb",
            "7e8fc69a345c434bbe474aadcbeb0335",
            "8858a30576104fc49f7b7f07249ba441",
            "9e006525cfcd4350aa372b97e2baf953"
          ]
        },
        "id": "TF7V7GBwbImF",
        "outputId": "1e105183-ea3d-4d42-aa7b-e91a5b98a770"
      },
      "outputs": [],
      "source": [
        "# Step 3: Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2pxmmSKGSKbh"
      },
      "outputs": [],
      "source": [
        "# Step 4: Define the tokenization function\n",
        "def tokenize_function(examples):\n",
        "    # Tokenize the text and include the labels\n",
        "    tokenized_output = tokenizer(examples['Text'], padding=\"max_length\", truncation=True)\n",
        "    tokenized_output['labels'] = examples['Label']  # Add labels to the tokenized output\n",
        "    return tokenized_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "39d2c7f74db041c19b844afca418fac8"
          ]
        },
        "id": "YZ5vI9jPSN1e",
        "outputId": "1931d6a0-ac5e-40a8-b166-8a3bbf826916"
      },
      "outputs": [],
      "source": [
        "# Step 5: Tokenize the dataset\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fen2SGGlSQO5",
        "outputId": "6a87087e-9776-479a-ec8e-b713184aab31"
      },
      "outputs": [],
      "source": [
        "# Step 6: Check if labels are correctly added\n",
        "print(\"Sample tokenized data:\", tokenized_datasets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hPB4HctkSWi0"
      },
      "outputs": [],
      "source": [
        "# Step 7: Split the dataset into training and validation sets\n",
        "train_testvalid = tokenized_datasets.train_test_split(test_size=0.2)\n",
        "train_dataset = train_testvalid['train']\n",
        "small_train_dataset = train_dataset.shuffle(seed=42).select([i for i in list(range(1000))])  # Use 1000 samples\n",
        "valid_dataset = train_testvalid['test']\n",
        "small_valid_dataset = valid_dataset.shuffle(seed=42).select([i for i in list(range(200))])  # Use 200 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "01f9e3e715244246b588c16e5457fdc6"
          ]
        },
        "id": "7x_v68fqSY6a",
        "outputId": "135a2eb8-a985-4351-e087-565689e85bb2"
      },
      "outputs": [],
      "source": [
        "# Step 8: Load the BERT model for sequence classification\n",
        "num_labels = len(sentiment_mapping)  # Ensure num_labels corresponds to your label mapping\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oCR-Jpz3SbnV"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"C:\\\\Users\\\\Aaditya Srivastava\\\\OneDrive\\\\Desktop\\\\BERT-model-main\",  # Output directory\n",
        "    eval_strategy=\"epoch\",  # Evaluate only at the end of each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,  # Try a higher batch size\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,  # Log every 100 steps for efficiency\n",
        "    gradient_accumulation_steps=2,  # Accumulate gradients to simulate a larger batch\n",
        "    fp16=True,  # Enable mixed precision training; disable if it slows down\n",
        "    report_to=\"none\", # Disable wandb logging\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2XKnyBN7V9zj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted') # Use weighted average for multiclass\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "0O_mMRPYSfq6",
        "outputId": "03481738-f5da-4983-9e7b-9f1e62f44973"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Step 8: Create a data collator\n",
        "# Data collators are used to pad the input sequences to the same length\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Step 9: Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_valid_dataset,\n",
        "    processing_class=tokenizer, # Use processing_class instead of tokenizer\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics # Add compute_metrics here\n",
        ")\n",
        "\n",
        "# Step 10: Start training\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqSHzfIASnCV"
      },
      "outputs": [],
      "source": [
        "# Perform evaluation\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed35ab32"
      },
      "outputs": [],
      "source": [
        "# Step 12: Evaluate the model with additional metrics\n",
        "print(\"Starting evaluation with more metrics...\")\n",
        "evaluation_results = trainer.evaluate(eval_dataset=small_valid_dataset)\n",
        "print(\"Evaluation results:\", evaluation_results)\n",
        "print(\"Evaluation finished.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cebbb09c"
      },
      "source": [
        "## Hyperparameter tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a73aa75"
      },
      "outputs": [],
      "source": [
        "# Step 1: Modify TrainingArguments hyperparameters\n",
        "training_args_tuned = TrainingArguments(\n",
        "    output_dir=\"C:\\\\Users\\\\Aaditya Srivastava\\\\OneDrive\\\\Desktop\\\\BERT-model-main_tuned\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Increased learning rate\n",
        "    per_device_train_batch_size=16,  # Increased batch size\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,  # Increased number of epochs\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs_tuned',\n",
        "    logging_steps=100,\n",
        "    gradient_accumulation_steps=1, # Reduced gradient accumulation\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# Step 2: Re-initialize the Trainer with updated TrainingArguments\n",
        "trainer_tuned = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_tuned,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_valid_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Step 3: Start training with the modified trainer\n",
        "print(\"Starting tuned training...\")\n",
        "trainer_tuned.train()\n",
        "print(\"Tuned training finished.\")\n",
        "\n",
        "# Step 4 & 5: Evaluate and print the results\n",
        "print(\"Starting tuned evaluation...\")\n",
        "evaluation_results_tuned = trainer_tuned.evaluate(eval_dataset=small_valid_dataset)\n",
        "print(\"Tuned evaluation results:\", evaluation_results_tuned)\n",
        "print(\"Tuned evaluation finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44731768"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create the directory\n",
        "save_directory = \"fine_tuned_bert_model\"\n",
        "os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "# Save the fine-tuned model\n",
        "trainer_tuned.model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2db8e11"
      },
      "source": [
        "## Prediction/Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba19c8c6"
      },
      "outputs": [],
      "source": [
        "# Step 13: Load the fine-tuned model and tokenizer\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(save_directory)\n",
        "\n",
        "# Step 14: Define a function for prediction\n",
        "def predict_sentiment(text):\n",
        "    # Tokenize the input text\n",
        "    inputs = loaded_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Make a prediction\n",
        "    outputs = loaded_model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = logits.argmax(dim=-1)\n",
        "\n",
        "    # Map the prediction back to sentiment label\n",
        "    # Create a reverse mapping from integer to sentiment label\n",
        "    reverse_sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
        "    predicted_sentiment = reverse_sentiment_mapping[predictions.item()]\n",
        "\n",
        "    return predicted_sentiment\n",
        "\n",
        "# Step 15: Test the prediction function with some examples\n",
        "example_texts = [\n",
        "    \"This is a fantastic movie!\",\n",
        "    \"I am not happy with the service.\",\n",
        "    \"The weather is neutral today.\",\n",
        "    \"This is really bad.\",\n",
        "    \"I love this product!\"\n",
        "]\n",
        "\n",
        "print(\"Predictions:\")\n",
        "for text in example_texts:\n",
        "    sentiment = predict_sentiment(text)\n",
        "    print(f\"Text: '{text}' -> Predicted Sentiment: {sentiment}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e6acd8f"
      },
      "outputs": [],
      "source": [
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76c65465"
      },
      "source": [
        "Now, let's create a simple interface using Gradio. This will create a web-based interface directly in your Colab output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0e4fe3b"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# We'll use the predict_sentiment function you already defined\n",
        "# from the previous section (Step 14).\n",
        "\n",
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_sentiment,  # Your prediction function\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter text here to analyze sentiment...\"),  # Text input with improved placeholder\n",
        "    outputs=\"text\",  # Text output for sentiment\n",
        "    title=\"BERT Sentiment Analysis\", # Slightly modified title\n",
        "    description=\"Enter text to analyze its sentiment (Positive, Negative, or Neutral) using a fine-tuned BERT model.\", # More descriptive\n",
        "    examples=[ # Add some examples\n",
        "        [\"I absolutely loved this movie, it was fantastic!\"],\n",
        "        [\"The service was terrible, I'm very disappointed.\"],\n",
        "        [\"The weather is cloudy today with a chance of rain.\"],\n",
        "        [\"This product exceeded my expectations.\"],\n",
        "        [\"I have no strong feelings about this.\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "print(\"Launching Gradio interface...\")\n",
        "interface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
